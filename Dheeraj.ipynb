{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvR7ppk77v31"
      },
      "source": [
        "### Importing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfcpIXQZN2Rh"
      },
      "source": [
        "### Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC8xCQuELWms"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from glob import glob\n",
        "import random\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYpVPmT5z7AP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpUsRQwOOL72"
      },
      "source": [
        "This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D57L-ovIKtI4"
      },
      "outputs": [],
      "source": [
        "# Defining the path for train and test images\n",
        "data_dir_train = pathlib.Path(\"/content/gdrive/MyDrive/AI_ML_DS/Google_Colab_Workspace/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\n",
        "data_dir_test = pathlib.Path('/content/gdrive/MyDrive/AI_ML_DS/Google_Colab_Workspace/Skin cancer ISIC The International Skin Imaging Collaboration/Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqksN1w5Fu-N"
      },
      "outputs": [],
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(image_count_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-CCnQ3R44kc"
      },
      "outputs": [],
      "source": [
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(image_count_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8HkfW3jPJun"
      },
      "source": [
        "### Load using keras.preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDBKZG3jPcMc"
      },
      "source": [
        "### Define some parameters for the loader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLfcXcZ9LjGv"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5f5y43GPog1"
      },
      "source": [
        "Pushing 80% of the images for training, and rest for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1BWmDzr7w-5"
      },
      "outputs": [],
      "source": [
        "## Write your train dataset here\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train, labels='inferred', label_mode='int',\n",
        "    class_names=None, color_mode='rgb', batch_size=32, image_size=(img_height,\n",
        "    img_width), shuffle=True, seed=123, validation_split=0.2, subset='training',\n",
        "    interpolation='bilinear', follow_links=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYch6-SR-i2g"
      },
      "outputs": [],
      "source": [
        "## Write your validation dataset here\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train, labels='inferred', label_mode='int',\n",
        "    class_names=None, color_mode='rgb', batch_size=32, image_size=(img_height,\n",
        "    img_width), shuffle=True, seed=123, validation_split=0.2, subset='validation',\n",
        "    interpolation='bilinear', follow_links=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk0RV7G7-nad"
      },
      "outputs": [],
      "source": [
        "# List out all the classes of skin cancer and store them in a list.\n",
        "# You can find the class names in the class_names attribute on these datasets.\n",
        "# These correspond to the directory names in alphabetical order.\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbsm5oYiQH_b"
      },
      "source": [
        "### Visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AiLd8L44WuEF"
      },
      "outputs": [],
      "source": [
        "### your code goes here, you can use training or validation data to visualize\n",
        "\n",
        "def generate_image_map(image_ds,btch_num=1):\n",
        "  # Dictionary to store one image per label (0 to 9)\n",
        "  label_image_map = {}\n",
        "  # Iterate through the dataset without limiting the number of batches\n",
        "  for images, labels in image_ds.skip(btch_num-1).take(1):\n",
        "      # Loop through each image and its corresponding label\n",
        "      for image, label in zip(images.numpy(), labels.numpy()):\n",
        "          # If we haven't already stored an image for this label\n",
        "          if label not in label_image_map:\n",
        "              label_image_map[label] = image  # Store the image with the unique label\n",
        "          # Stop once we have one image for each label (0 to 9)\n",
        "          if len(label_image_map) == 10:\n",
        "              break  # Exit the inner loop if all 10 labels are found\n",
        "      if len(label_image_map) == 10:\n",
        "          break  # Exit outer loop once all labels are covered\n",
        "  # Sort the dictionary by keys\n",
        "  sorted_image_map=dict(sorted(label_image_map.items()))\n",
        "  # Display the keys of the dictionary to check which labels have been collected\n",
        "  print(\"Labels found:\", sorted_image_map.keys())\n",
        "  return sorted_image_map\n",
        "\n",
        "\n",
        "def plt_sample_img(class_names, label_image_map):\n",
        "  plt.figure(figsize=(20, 10))\n",
        "  for idx, (label, image) in enumerate(label_image_map.items()):\n",
        "      plt.subplot(2, 5, idx + 1)  # Create a 2x5 grid for the images\n",
        "      plt.imshow(image.astype(\"uint8\"))  # Display the image\n",
        "      plt.title(f\"Class: {class_names[label]}\")  # Display the class name\n",
        "      plt.axis('off')  # Turn off the axis\n",
        "  # Show the plot with all images\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBQ1-7f7MCrS"
      },
      "outputs": [],
      "source": [
        "# Genarate random batch number between 0 and 10\n",
        "btch_num=random.randint(1,11)\n",
        "btch_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7l2F6Gtfivqe"
      },
      "outputs": [],
      "source": [
        "# Visualize Train Data\n",
        "train_image_map=generate_image_map(train_ds,btch_num)\n",
        "plt_sample_img(class_names,train_image_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5gohuN3vkchd"
      },
      "outputs": [],
      "source": [
        "# Visualize Validation Data\n",
        "val_image_map=generate_image_map(val_ds,btch_num)\n",
        "plt_sample_img(class_names,val_image_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cAZPYaeQjQy"
      },
      "source": [
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wZlKRBEGNtU"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCjfC68MerL8"
      },
      "source": [
        "## Model 1 - Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JEAF6-sRyz8"
      },
      "source": [
        "### Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ync9xoW7GZgn"
      },
      "outputs": [],
      "source": [
        "### Your code goes here\n",
        "base_model=Sequential(name=\"Melanoma_Detection_Model\")\n",
        "# Adding Rescaling layer\n",
        "base_model.add(layers.Rescaling(1.0/255.0 , offset=0.0 , input_shape=(img_height,img_width,3), name=\"Rescaling_Layer\"))\n",
        "# First Part\n",
        "base_model.add(layers.Conv2D(filters=16,kernel_size=(3,3),padding=\"same\",activation=\"relu\",  name=\"Conv2D_Layer_1\"))  # adding first Convolution layer\n",
        "base_model.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_1\")) # adding first Max Pooling layer\n",
        "# Second Part\n",
        "base_model.add(layers.Conv2D(filters=32,kernel_size=(3,3),padding=\"same\",activation=\"relu\", name=\"Conv2D_Layer_2\")) # adding second Convolution layer\n",
        "base_model.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_2\")) # adding second Max Pooling layer\n",
        "# Third Part\n",
        "base_model.add(layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\", name=\"Conv2D_Layer_3\")) # adding second Convolution layer\n",
        "base_model.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_3\")) # adding second Max Pooling layer\n",
        "# Flattening the output\n",
        "base_model.add(layers.Flatten(name=\"Flatten_Layer\"))\n",
        "# Fully Connected Layer\n",
        "base_model.add(layers.Dense(units=128,activation=\"relu\",name=\"FC_Layer_1\") )# adding first fully connected layer\n",
        "# Output Layer\n",
        "base_model.add(layers.Dense(units=len(class_names),activation=\"softmax\",name=\"Output_Layer\")) # adding output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDKzJmHwSCtt"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB8wKtiPGe1j"
      },
      "outputs": [],
      "source": [
        "### Todo, choose an appropirate optimiser and loss function\n",
        "base_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZGWN4MZGhtJ"
      },
      "outputs": [],
      "source": [
        "# View the summary of all layers\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljD_83rwSl5O"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kkfw2rJXGlYC"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "base_model_history = base_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3679V8OShSE"
      },
      "source": [
        "### Visualizing training results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1xkgk5nGubz"
      },
      "outputs": [],
      "source": [
        "acc = base_model_history.history['accuracy']\n",
        "val_acc = base_model_history.history['val_accuracy']\n",
        "\n",
        "loss = base_model_history.history['loss']\n",
        "val_loss = base_model_history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvPphJYuSZhK"
      },
      "source": [
        "#### Todo: Write your findings after the model fit, see if there is an evidence of model overfit or underfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vRTPbJEn-pX"
      },
      "source": [
        "### Write your findings here\n",
        "- Training accuracy steadily improve to 88-90% by the 20th epoch, indicating that - the model is learning and fitting the training data well.\n",
        "- The validation accuracy, on the other hand, peaks at around 55% and - then stagnates or decreases by the 20th epoch. This shows that the model - is not generalizing well to unseen data and starts to overfit after a - certain point.\n",
        "- While the training loss continues to drop, the validation loss increases significantly over time by the 20th epoch.\n",
        "\n",
        "The model is overfitting, as indicated by the widening gap between the training and validation performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfRVHDPmezMA"
      },
      "source": [
        "## Model 2 - Base Model with Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcLgl0DInxFi"
      },
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22hljAl6GykA"
      },
      "outputs": [],
      "source": [
        "data_augmentation = Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\", seed=123 ),\n",
        "  layers.RandomRotation(0.2, seed=123),\n",
        "  layers.RandomZoom(0.2, seed=123),\n",
        "] , name=\"Data_Augmentation_Layer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEjPWh8GG0C7"
      },
      "outputs": [],
      "source": [
        "random_num=random.randint(1,11)\n",
        "plt.figure(figsize=(10, 8))\n",
        "for images, _ in train_ds.skip(random_num-1).take(random_num):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images) # data augmenatation\n",
        "    ax = plt.subplot(3, 3, i + 1) # Create a 3x3 grid for the images\n",
        "    plt.imshow(augmented_images[random_num].numpy().astype(\"uint8\")) # Display the image\n",
        "    plt.axis(\"off\") # Turn off the axis\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhKDHlUdTuSX"
      },
      "source": [
        "### Create the model, compile and train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-exExeYZoRK"
      },
      "outputs": [],
      "source": [
        "aug_layer_model=Sequential(name=\"Melanoma_Detection_Model\")\n",
        "# Adding Rescaling layer\n",
        "aug_layer_model.add(layers.Rescaling(1.0/255.0 , offset=0.0 , input_shape=(img_height,img_width,3), name=\"Rescaling_Layer\"))\n",
        "# Adding Data Augmentation\n",
        "aug_layer_model.add( data_augmentation )\n",
        "# First Part\n",
        "aug_layer_model.add(layers.Conv2D(filters=16,kernel_size=(3,3),padding=\"same\",activation=\"relu\",  name=\"Conv2D_Layer_1\"))  # adding first Convolution layer\n",
        "aug_layer_model.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_1\")) # adding first Max Pooling layer\n",
        "# Second Part\n",
        "aug_layer_model.add(layers.Conv2D(filters=32,kernel_size=(3,3),padding=\"same\",activation=\"relu\", name=\"Conv2D_Layer_2\")) # adding second Convolution layer\n",
        "aug_layer_model.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_2\")) # adding second Max Pooling layer\n",
        "# Third Part\n",
        "aug_layer_model.add(layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\", name=\"Conv2D_Layer_3\")) # adding second Convolution layer\n",
        "aug_layer_model.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_3\")) # adding second Max Pooling layer\n",
        "aug_layer_model.add(layers.Dropout(0.30 ,name=\"Dropout_1\") )# adding dropouts\n",
        "# Flattening the output\n",
        "aug_layer_model.add(layers.Flatten(name=\"Flatten_Layer\"))\n",
        "# Fully Connected Layer\n",
        "aug_layer_model.add(layers.Dense(units=128,activation=\"relu\",name=\"FC_Layer_1\") )# adding first fully connected layer\n",
        "aug_layer_model.add(layers.Dropout(0.30,name=\"Dropout_2\")) # adding dropouts\n",
        "# Output Layer\n",
        "aug_layer_model.add(layers.Dense(units=len(class_names),activation=\"softmax\",name=\"Output_Layer\")) # adding output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfUWFp96UIAN"
      },
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-7yTm8IG8zR"
      },
      "outputs": [],
      "source": [
        "aug_layer_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-3F9FXiy2NG"
      },
      "outputs": [],
      "source": [
        "aug_layer_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC-D_RWOURp6"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcPfkUASHBf9"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "aug_layer_history = aug_layer_model.fit(train_ds ,\n",
        "                    batch_size=batch_size ,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=val_ds,\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhNOKtSyUYzC"
      },
      "source": [
        "### Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjN_F4QxHIsh"
      },
      "outputs": [],
      "source": [
        "acc = aug_layer_history.history['accuracy']\n",
        "val_acc = aug_layer_history.history['val_accuracy']\n",
        "\n",
        "loss = aug_layer_history.history['loss']\n",
        "val_loss = aug_layer_history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-AUR_b7UcaK"
      },
      "source": [
        "Summary:\n",
        "- Training accuracy and validation accuracy are almost the same but are both quite low, indicating that the model is likely underfitting.\n",
        "- Training loss is very low, while the validation loss fluctuates significantly.\n",
        "- These results suggest that the current model is not performing well and requires improvement.\n",
        "- To add on, addressing the issue of class imbalance could further - improve the model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muRCSD69jnil"
      },
      "source": [
        "## Model 3 - Base Model with Data Augmentation after fixing Data imbalacing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TdDi4u-VTkW"
      },
      "source": [
        "### **Todo:** Find the distribution of classes in the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAhwYgtTQRzq"
      },
      "outputs": [],
      "source": [
        "list_images = []\n",
        "for i in class_names:\n",
        "    list_images.append(len(list(data_dir_train.glob(i+'/*.jpg'))))\n",
        "\n",
        "data = {'Class Names': class_names, 'Image Count': list_images}\n",
        "original_df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAX7TmWQipE_"
      },
      "outputs": [],
      "source": [
        "original_df.head(9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4csQL1dvO0b2"
      },
      "source": [
        "#### - Which class has the least number of samples?\n",
        "Answer - seborrheic keratosis - 77\n",
        "#### - Which classes dominate the data in terms proportionate number of samples?\n",
        "Answer - pigmented benign keratosis - 462\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb-stKyHPf8v"
      },
      "source": [
        "#### Rectify the class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItAg4rU-SzJh"
      },
      "outputs": [],
      "source": [
        "!pip install Augmentor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZKzTe3zWL4O"
      },
      "source": [
        "To use `Augmentor`, the following general procedure is followed:\n",
        "\n",
        "1. Instantiate a `Pipeline` object pointing to a directory containing your initial image data set.<br>\n",
        "2. Define a number of operations to perform on this data set using your `Pipeline` object.<br>\n",
        "3. Execute these operations by calling the `Pipeline’s` `sample()` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Egt9EHjR-Dd"
      },
      "outputs": [],
      "source": [
        "path_to_training_dataset=\"/content/gdrive/MyDrive/AI_ML_DS/Google_Colab_Workspace/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    class_path = path_to_training_dataset + i + '/output'\n",
        "    # Check if 'output' folder exists and has the required number of images\n",
        "    if os.path.exists(class_path) and len(os.listdir(class_path)) >= target_sample_size:\n",
        "        print(f\"Augmentation already done for class '{i}', skipping augmentation.\")\n",
        "    else:\n",
        "        print(f\"Augmenting class '{i}' as required samples are not present.\")\n",
        "    # Create an Augmentor pipeline for the class if augmentation is needed\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcBIFZGbWuFa"
      },
      "source": [
        "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxWcMqZhdRWz"
      },
      "outputs": [],
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ5KarKq4kWJ"
      },
      "source": [
        "### Lets see the distribution of augmented data after adding new images to the original training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6tODrYIY2nxJ"
      },
      "outputs": [],
      "source": [
        "path_list_new = [x for x in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "path_list_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nZvVdF7g3E1z"
      },
      "outputs": [],
      "source": [
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "lesion_list_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okcqVFAA2nxK"
      },
      "outputs": [],
      "source": [
        "dataframe_dict_new = dict(zip(path_list_new, lesion_list_new))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njzBxTNT2nxK"
      },
      "outputs": [],
      "source": [
        "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
        "new_df = pd.concat([original_df,df2],ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5j45rmxd2nxK"
      },
      "outputs": [],
      "source": [
        "new_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NirFBvGPmgI"
      },
      "source": [
        "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EnspeMbRWNs"
      },
      "source": [
        "### **Todo**: Train the model on the data created using Augmentor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFcj1XgndRWz"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0haOU11Ey8ey"
      },
      "source": [
        "#### **Todo:** Create a training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4ZY11judRWz"
      },
      "outputs": [],
      "source": [
        "data_dir_train=\"/content/gdrive/MyDrive/AI_ML_DS/Google_Colab_Workspace/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'training',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwNJVDuBP5kf"
      },
      "source": [
        "#### **Todo:** Create a validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX191d_3dRW0"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset ='validation',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaoWeOEpVjqH"
      },
      "source": [
        "### **Todo:** Create your model (make sure to include normalization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEz763y81Ex0"
      },
      "source": [
        "#### Create your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp79sHb7NUmx"
      },
      "outputs": [],
      "source": [
        "class_blncd_mdl = Sequential(name=\"Melanoma_Detection_Model\")\n",
        "\n",
        "# Adding Rescaling layer\n",
        "class_blncd_mdl.add(layers.Rescaling(1.0/255.0, offset=0.0, input_shape=(img_height, img_width, 3), name=\"Rescaling_Layer\"))\n",
        "\n",
        "# Adding Data Augmentation\n",
        "class_blncd_mdl.add(data_augmentation)\n",
        "\n",
        "# First Part\n",
        "class_blncd_mdl.add(layers.Conv2D(filters=16, kernel_size=(3,3),padding=\"same\", name=\"Conv2D_Layer_1\"))  # adding first Convolution layer\n",
        "class_blncd_mdl.add(layers.BatchNormalization(name=\"BatchNorm_Layer_1\"))  # adding normalization\n",
        "class_blncd_mdl.add(layers.Activation('relu', name=\"ReLU_Activation_1\"))\n",
        "class_blncd_mdl.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_1\"))  # adding first Max Pooling layer\n",
        "\n",
        "# Second Part\n",
        "class_blncd_mdl.add(layers.Conv2D(filters=32, kernel_size=(3,3),padding=\"same\", name=\"Conv2D_Layer_2\"))  # adding second Convolution layer\n",
        "class_blncd_mdl.add(layers.BatchNormalization(name=\"BatchNorm_Layer_2\"))  # adding normalization\n",
        "class_blncd_mdl.add(layers.Activation('relu', name=\"ReLU_Activation_2\"))\n",
        "class_blncd_mdl.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_2\"))  # adding second Max Pooling layer\n",
        "\n",
        "# Third Part\n",
        "class_blncd_mdl.add(layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\", name=\"Conv2D_Layer_3\")) # adding second Convolution layer\n",
        "class_blncd_mdl.add(layers.BatchNormalization(name=\"BatchNorm_Layer_3\"))  # adding normalization\n",
        "class_blncd_mdl.add(layers.Activation('relu', name=\"ReLU_Activation_3\"))\n",
        "class_blncd_mdl.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_3\")) # adding second Max Pooling layer\n",
        "class_blncd_mdl.add(layers.Dropout(0.30 ,name=\"Dropout_1\") )# adding dropouts\n",
        "\n",
        "# Flattening the output\n",
        "class_blncd_mdl.add(layers.Flatten(name=\"Flatten_Layer\"))\n",
        "\n",
        "# Fully Connected Layer\n",
        "class_blncd_mdl.add(layers.Dense(units=128, name=\"FC_Layer_1\"))\n",
        "class_blncd_mdl.add(layers.BatchNormalization(name=\"BatchNorm_Layer_4\"))  # adding normalization\n",
        "class_blncd_mdl.add(layers.Activation('relu', name=\"ReLU_Activation_4\"))\n",
        "class_blncd_mdl.add(layers.Dropout(0.30, name=\"Dropout_2\"))  # adding dropout\n",
        "\n",
        "# Output Layer\n",
        "class_blncd_mdl.add(layers.Dense(units=len(class_names), activation=\"softmax\", name=\"Output_Layer\"))  # adding output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu5N9LxkVx1B"
      },
      "source": [
        "#### **Todo:** Compile your model (Choose optimizer and loss function appropriately)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H47GWmLbdRW1"
      },
      "outputs": [],
      "source": [
        "class_blncd_mdl.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhfGPeNkt4uV"
      },
      "outputs": [],
      "source": [
        "# View the summary of all layers\n",
        "class_blncd_mdl.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gS-Y1bJV7uy"
      },
      "source": [
        "#### **Todo:**  Train your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcV6OdI4dRW1"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "## Your code goes here, use 30 epochs.\n",
        "class_balanced_history = class_blncd_mdl.fit(train_ds ,\n",
        "                    batch_size=batch_size ,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=val_ds,\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuvfCTsBWLMp"
      },
      "source": [
        "#### **Todo:**  Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCTXwfkTdRW1"
      },
      "outputs": [],
      "source": [
        "acc = class_balanced_history.history['accuracy']\n",
        "val_acc = class_balanced_history.history['val_accuracy']\n",
        "\n",
        "loss = class_balanced_history.history['loss']\n",
        "val_loss = class_balanced_history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCyb8ynMXI5t"
      },
      "source": [
        "## Model 4 - Include Callbacks and adjust Dropouts ( gradually increase dropout percentages )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FdJQqDxWf4b"
      },
      "outputs": [],
      "source": [
        "## your code goes here\n",
        "lr_control_model = Sequential(name=\"Melanoma_Detection_Model\")\n",
        "\n",
        "# Adding Rescaling layer\n",
        "lr_control_model.add(layers.Rescaling(1.0/255.0, offset=0.0, input_shape=(img_height, img_width, 3), name=\"Rescaling_Layer\"))\n",
        "\n",
        "# Adding Data Augmentation\n",
        "lr_control_model.add(data_augmentation)\n",
        "\n",
        "# First Part\n",
        "lr_control_model.add(layers.Conv2D(filters=16, kernel_size=(3,3), padding=\"same\",  name=\"Conv2D_Layer_1\"))  # adding first Convolution layer\n",
        "lr_control_model.add(layers.BatchNormalization(name=\"BatchNorm_Layer_1\"))  # adding normalization\n",
        "lr_control_model.add(layers.Activation('relu', name=\"ReLU_Activation_1\"))\n",
        "lr_control_model.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_1\"))  # adding first Max Pooling layer\n",
        "\n",
        "# Second Part\n",
        "lr_control_model.add(layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", name=\"Conv2D_Layer_2\"))  # adding second Convolution layer\n",
        "lr_control_model.add(layers.BatchNormalization(name=\"BatchNorm_Layer_2\"))  # adding normalization\n",
        "lr_control_model.add(layers.Activation('relu', name=\"ReLU_Activation_2\"))\n",
        "lr_control_model.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_2\"))  # adding second Max Pooling layer\n",
        "\n",
        "# Third Part\n",
        "lr_control_model.add(layers.Conv2D(filters=64,kernel_size=(3,3), padding=\"same\",activation=\"relu\", name=\"Conv2D_Layer_3\")) # adding second Convolution layer\n",
        "lr_control_model.add(layers.BatchNormalization(name=\"BatchNorm_Layer_3\"))  # adding normalization\n",
        "lr_control_model.add(layers.Activation('relu', name=\"ReLU_Activation_3\"))\n",
        "lr_control_model.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_3\")) # adding second Max Pooling layer\n",
        "lr_control_model.add(layers.Dropout(0.30 ,name=\"Dropout_1\") )# adding dropouts\n",
        "\n",
        "# Flattening the output\n",
        "lr_control_model.add(layers.Flatten(name=\"Flatten_Layer\"))\n",
        "\n",
        "# Fully Connected Layer\n",
        "lr_control_model.add(layers.Dense(units=128, name=\"FC_Layer_1\"))\n",
        "lr_control_model.add(layers.BatchNormalization(name=\"BatchNorm_Layer_4\"))  # adding normalization\n",
        "lr_control_model.add(layers.Activation('relu', name=\"ReLU_Activation_4\"))\n",
        "lr_control_model.add(layers.Dropout(0.40, name=\"Dropout_2\"))  # adding dropout\n",
        "\n",
        "# Output Layer\n",
        "lr_control_model.add(layers.Dense(units=len(class_names), activation=\"softmax\", name=\"Output_Layer\"))  # adding output layer\n",
        "\n",
        "# Compile the model\n",
        "lr_control_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set callbacks\n",
        "learn_control = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                  patience=3,\n",
        "                                  verbose=1,\n",
        "                                  factor=0.1,\n",
        "                                  min_lr=1e-7)\n",
        "\n",
        "# View the summary of all layers\n",
        "lr_control_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBQbOzlPXUzE"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt0b9c0WXUzE"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "lr_control_history = lr_control_model.fit(train_ds ,\n",
        "                    batch_size=batch_size ,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[learn_control],\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0F0INN20KCR"
      },
      "source": [
        "Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3pJgsn_0KCS"
      },
      "outputs": [],
      "source": [
        "acc = lr_control_history.history['accuracy']\n",
        "val_acc = lr_control_history.history['val_accuracy']\n",
        "\n",
        "loss = lr_control_history.history['loss']\n",
        "val_loss = lr_control_history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Way4lakC4_p0"
      },
      "source": [
        "#### Analyze your results here. Did you get rid of underfitting/overfitting? Did class rebalance help?\n",
        "\n",
        "In Model 1, we observed significant overfitting, with high training accuracy (0.84) but much lower validation accuracy (0.55). Adding data augmentation in Model 2 helped reduce the gap between training and validation accuracy, but underfitting became a concern. Model 3, with class rebalancing, further reduced overfitting but slightly hindered validation performance.\n",
        "\n",
        "Model 4, which introduced controlled learning rate, showed improved generalization, as indicated by a more balanced train and validation accuracy (0.63 vs. 0.61). Overall, class rebalancing and learning rate control contributed positively to the model’s stability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjnAMylUpwBT"
      },
      "source": [
        "## Model 5 - Let's try with little increased Learning rate and also include Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gWCZT_5thoK"
      },
      "source": [
        "Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsDi33Pwp2lJ"
      },
      "outputs": [],
      "source": [
        "increased_lr_ctrl_mdl = Sequential(name=\"Melanoma_Detection_Model\")\n",
        "\n",
        "# Adding Rescaling layer\n",
        "increased_lr_ctrl_mdl.add(layers.Rescaling(1.0/255.0, offset=0.0, input_shape=(img_height, img_width, 3), name=\"Rescaling_Layer\"))\n",
        "\n",
        "# Adding Data Augmentation\n",
        "increased_lr_ctrl_mdl.add(data_augmentation)\n",
        "\n",
        "# First Part\n",
        "increased_lr_ctrl_mdl.add(layers.Conv2D(filters=16, kernel_size=(3,3), padding=\"same\",  name=\"Conv2D_Layer_1\"))  # adding first Convolution layer\n",
        "increased_lr_ctrl_mdl.add(layers.BatchNormalization(name=\"BatchNorm_Layer_1\"))  # adding normalization\n",
        "increased_lr_ctrl_mdl.add(layers.Activation('relu', name=\"ReLU_Activation_1\"))\n",
        "increased_lr_ctrl_mdl.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_1\"))  # adding first Max Pooling layer\n",
        "\n",
        "# Second Part\n",
        "increased_lr_ctrl_mdl.add(layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", name=\"Conv2D_Layer_2\"))  # adding second Convolution layer\n",
        "increased_lr_ctrl_mdl.add(layers.BatchNormalization(name=\"BatchNorm_Layer_2\"))  # adding normalization\n",
        "increased_lr_ctrl_mdl.add(layers.Activation('relu', name=\"ReLU_Activation_2\"))\n",
        "increased_lr_ctrl_mdl.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_2\"))  # adding second Max Pooling layer\n",
        "\n",
        "# Third Part\n",
        "increased_lr_ctrl_mdl.add(layers.Conv2D(filters=64,kernel_size=(3,3), padding=\"same\",activation=\"relu\", name=\"Conv2D_Layer_3\")) # adding second Convolution layer\n",
        "increased_lr_ctrl_mdl.add(layers.BatchNormalization(name=\"BatchNorm_Layer_3\"))  # adding normalization\n",
        "increased_lr_ctrl_mdl.add(layers.Activation('relu', name=\"ReLU_Activation_3\"))\n",
        "increased_lr_ctrl_mdl.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_3\")) # adding second Max Pooling layer\n",
        "increased_lr_ctrl_mdl.add(layers.Dropout(0.30 ,name=\"Dropout_1\") )# adding dropouts\n",
        "\n",
        "# Flattening the output\n",
        "increased_lr_ctrl_mdl.add(layers.Flatten(name=\"Flatten_Layer\"))\n",
        "\n",
        "# Fully Connected Layer\n",
        "increased_lr_ctrl_mdl.add(layers.Dense(units=128, name=\"FC_Layer_1\"))\n",
        "increased_lr_ctrl_mdl.add(layers.BatchNormalization(name=\"BatchNorm_Layer_4\"))  # adding normalization\n",
        "increased_lr_ctrl_mdl.add(layers.Activation('relu', name=\"ReLU_Activation_4\"))\n",
        "increased_lr_ctrl_mdl.add(layers.Dropout(0.40, name=\"Dropout_2\"))  # adding dropout\n",
        "\n",
        "# Output Layer\n",
        "increased_lr_ctrl_mdl.add(layers.Dense(units=len(class_names), activation=\"softmax\", name=\"Output_Layer\"))  # adding output layer\n",
        "\n",
        "# Compile the model\n",
        "increased_lr_ctrl_mdl.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), # Reduce learning rate\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Set callbacks\n",
        "learn_control = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                  patience=3,\n",
        "                                  verbose=1,\n",
        "                                  factor=0.1,\n",
        "                                  min_lr=1e-7)\n",
        "\n",
        "# View the summary of all layers\n",
        "increased_lr_ctrl_mdl.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s7TfcKSqtUP"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcGYOYJyqsAP"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "increased_lr_control_history = increased_lr_ctrl_mdl.fit(train_ds ,\n",
        "                    batch_size=batch_size ,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[learn_control],\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8qKWW4G1jmy"
      },
      "source": [
        "Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBbDt_Oo1jmy"
      },
      "outputs": [],
      "source": [
        "acc = increased_lr_control_history.history['accuracy']\n",
        "val_acc = increased_lr_control_history.history['val_accuracy']\n",
        "\n",
        "loss = increased_lr_control_history.history['loss']\n",
        "val_loss = increased_lr_control_history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4Fnz-gs805m"
      },
      "source": [
        "## Model 6 - Default Learning Rate and increased Epoch Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QzZfGOb805o"
      },
      "outputs": [],
      "source": [
        "more_epoch_model = Sequential(name=\"Melanoma_Detection_Model\")\n",
        "\n",
        "# Adding Rescaling layer\n",
        "more_epoch_model.add(layers.Rescaling(1.0/255.0, offset=0.0, input_shape=(img_height, img_width, 3), name=\"Rescaling_Layer\"))\n",
        "\n",
        "# Adding Data Augmentation\n",
        "more_epoch_model.add(data_augmentation)\n",
        "\n",
        "# First Part\n",
        "more_epoch_model.add(layers.Conv2D(filters=16, kernel_size=(3,3), padding=\"same\",  name=\"Conv2D_Layer_1\"))  # adding first Convolution layer\n",
        "more_epoch_model.add(layers.BatchNormalization(name=\"BatchNorm_Layer_1\"))  # adding normalization\n",
        "more_epoch_model.add(layers.Activation('relu', name=\"ReLU_Activation_1\"))\n",
        "more_epoch_model.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_1\"))  # adding first Max Pooling layer\n",
        "\n",
        "# Second Part\n",
        "more_epoch_model.add(layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", name=\"Conv2D_Layer_2\"))  # adding second Convolution layer\n",
        "more_epoch_model.add(layers.BatchNormalization(name=\"BatchNorm_Layer_2\"))  # adding normalization\n",
        "more_epoch_model.add(layers.Activation('relu', name=\"ReLU_Activation_2\"))\n",
        "more_epoch_model.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_2\"))  # adding second Max Pooling layer\n",
        "\n",
        "# Third Part\n",
        "more_epoch_model.add(layers.Conv2D(filters=64,kernel_size=(3,3), padding=\"same\",activation=\"relu\", name=\"Conv2D_Layer_3\")) # adding second Convolution layer\n",
        "more_epoch_model.add(layers.BatchNormalization(name=\"BatchNorm_Layer_3\"))  # adding normalization\n",
        "more_epoch_model.add(layers.Activation('relu', name=\"ReLU_Activation_3\"))\n",
        "more_epoch_model.add(layers.MaxPooling2D(pool_size=(2,2), name=\"MaxPooling2D_Layer_3\")) # adding second Max Pooling layer\n",
        "more_epoch_model.add(layers.Dropout(0.30 ,name=\"Dropout_1\") )# adding dropouts\n",
        "\n",
        "# Flattening the output\n",
        "more_epoch_model.add(layers.Flatten(name=\"Flatten_Layer\"))\n",
        "\n",
        "# Fully Connected Layer\n",
        "more_epoch_model.add(layers.Dense(units=128, name=\"FC_Layer_1\"))\n",
        "more_epoch_model.add(layers.BatchNormalization(name=\"BatchNorm_Layer_4\"))  # adding normalization\n",
        "more_epoch_model.add(layers.Activation('relu', name=\"ReLU_Activation_4\"))\n",
        "more_epoch_model.add(layers.Dropout(0.40, name=\"Dropout_2\"))  # adding dropout\n",
        "\n",
        "# Output Layer\n",
        "more_epoch_model.add(layers.Dense(units=len(class_names), activation=\"softmax\", name=\"Output_Layer\"))  # adding output layer\n",
        "\n",
        "# Compile the model\n",
        "more_epoch_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set callbacks\n",
        "learn_control = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                  patience=3,\n",
        "                                  verbose=1,\n",
        "                                  factor=0.1,\n",
        "                                  min_lr=1e-7)\n",
        "\n",
        "# View the summary of all layers\n",
        "more_epoch_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFAk5oA7805p"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiAIxwFw805p"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "more_epoch_history = more_epoch_model.fit(train_ds ,\n",
        "                    batch_size=batch_size ,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[learn_control],\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VduqIGh805q"
      },
      "source": [
        "Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAgcD2kz805r"
      },
      "outputs": [],
      "source": [
        "acc = more_epoch_history.history['accuracy']\n",
        "val_acc = more_epoch_history.history['val_accuracy']\n",
        "\n",
        "loss = more_epoch_history.history['loss']\n",
        "val_loss = more_epoch_history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKzGu2rgYIso"
      },
      "source": [
        "## Model 7 - Six Convolution layers with Batch Normalization and dropouts\n",
        "Max Pooling layer after every two Convolution Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kURRLDCAYIsq"
      },
      "source": [
        "Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz76-w17YIsq"
      },
      "outputs": [],
      "source": [
        "# Create the Model\n",
        "six_layers_model = Sequential(name=\"Melanoma_Detection_Model_More_Layers\")\n",
        "\n",
        "# Adding Rescaling layer\n",
        "six_layers_model.add(layers.Rescaling(1.0/255.0, offset=0.0, input_shape=(img_height, img_width, 3), name=\"Rescaling_Layer\"))\n",
        "\n",
        "# Adding Data Augmentation\n",
        "six_layers_model.add(data_augmentation)\n",
        "\n",
        "# First Part\n",
        "six_layers_model.add(layers.Conv2D(filters=16, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_16F_1\"))  # adding Convolution layer\n",
        "six_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "six_layers_model.add(layers.Activation('relu'))\n",
        "six_layers_model.add(layers.Conv2D(filters=16, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_16F_2\"))  # adding Convolution layer\n",
        "six_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "six_layers_model.add(layers.Activation('relu'))\n",
        "six_layers_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Second Part\n",
        "six_layers_model.add(layers.Conv2D(filters=32, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_32F_1\"))  # adding Convolution layer\n",
        "six_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "six_layers_model.add(layers.Activation('relu'))\n",
        "six_layers_model.add(layers.Conv2D(filters=32, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_32F_2\"))  # adding Convolution layer\n",
        "six_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "six_layers_model.add(layers.Activation('relu'))\n",
        "six_layers_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Third Part\n",
        "six_layers_model.add(layers.Conv2D(filters=64, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_64F_1\"))  # adding Convolution layer\n",
        "six_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "six_layers_model.add(layers.Activation('relu'))\n",
        "six_layers_model.add(layers.Conv2D(filters=64, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_64F_2\"))  # adding Convolution layer\n",
        "six_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "six_layers_model.add(layers.Activation('relu'))\n",
        "six_layers_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "\n",
        "# Adding dropouts\n",
        "six_layers_model.add(layers.Dropout(0.30))# adding dropouts\n",
        "\n",
        "# Flattening the output\n",
        "six_layers_model.add(layers.Flatten(name=\"Flatten_Layer\"))\n",
        "\n",
        "# Fully Connected Layer\n",
        "six_layers_model.add(layers.Dense(units=128, name=\"FC_Layer_128N\"))\n",
        "six_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "six_layers_model.add(layers.Activation('relu'))\n",
        "\n",
        "# Adding dropouts\n",
        "six_layers_model.add(layers.Dropout(0.40))  # adding dropout\n",
        "\n",
        "# Output Layer\n",
        "six_layers_model.add(layers.Dense(units=len(class_names), activation=\"softmax\", name=\"Output_Layer\"))  # adding output layer\n",
        "\n",
        "# Compile the model\n",
        "six_layers_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set callbacks\n",
        "learn_control = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                  patience=3,\n",
        "                                  verbose=1,\n",
        "                                  factor=0.1,\n",
        "                                  min_lr=1e-7)\n",
        "\n",
        "# View the summary of all layers\n",
        "six_layers_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJyIUL26YIsr"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW9KOh5K4FAq"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "six_layers_history = six_layers_model.fit(train_ds ,\n",
        "                    batch_size=batch_size ,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[learn_control],\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocZuKRp0YIss"
      },
      "source": [
        "Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuqeyyH0YIst"
      },
      "outputs": [],
      "source": [
        "acc = six_layers_history.history['accuracy']\n",
        "val_acc = six_layers_history.history['val_accuracy']\n",
        "\n",
        "loss = six_layers_history.history['loss']\n",
        "val_loss = six_layers_history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9PGCS6c8_lr"
      },
      "source": [
        "## Model 8 - Eight Convolution layers with Batch Normalization and dropouts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6kAQQqi8_lr"
      },
      "source": [
        "Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWOGvjwx8_lr"
      },
      "outputs": [],
      "source": [
        "# Create the Model\n",
        "eight_layers_model = Sequential(name=\"Melanoma_Detection_Model_More_Layers\")\n",
        "\n",
        "# Adding Rescaling layer\n",
        "eight_layers_model.add(layers.Rescaling(1.0/255.0, offset=0.0, input_shape=(img_height, img_width, 3), name=\"Rescaling_Layer\"))\n",
        "\n",
        "# Adding Data Augmentation\n",
        "eight_layers_model.add(data_augmentation)\n",
        "\n",
        "# First Part\n",
        "eight_layers_model.add(layers.Conv2D(filters=16, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_16F_1\"))  # adding Convolution layer\n",
        "eight_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "eight_layers_model.add(layers.Activation('relu'))\n",
        "eight_layers_model.add(layers.Conv2D(filters=16, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_16F_2\"))  # adding Convolution layer\n",
        "eight_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "eight_layers_model.add(layers.Activation('relu'))\n",
        "eight_layers_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Second Part\n",
        "eight_layers_model.add(layers.Conv2D(filters=32, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_32F_1\"))  # adding Convolution layer\n",
        "eight_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "eight_layers_model.add(layers.Activation('relu'))\n",
        "eight_layers_model.add(layers.Conv2D(filters=32, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_32F_2\"))  # adding Convolution layer\n",
        "eight_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "eight_layers_model.add(layers.Activation('relu'))\n",
        "eight_layers_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Third Part\n",
        "eight_layers_model.add(layers.Conv2D(filters=64, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_64F_1\"))  # adding Convolution layer\n",
        "eight_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "eight_layers_model.add(layers.Activation('relu'))\n",
        "eight_layers_model.add(layers.Conv2D(filters=64, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_64F_2\"))  # adding Convolution layer\n",
        "eight_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "eight_layers_model.add(layers.Activation('relu'))\n",
        "eight_layers_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Fourth Part\n",
        "eight_layers_model.add(layers.Conv2D(filters=128, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_128F_1\"))  # adding Convolution layer\n",
        "eight_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "eight_layers_model.add(layers.Activation('relu'))\n",
        "eight_layers_model.add(layers.Conv2D(filters=128, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_128F_2\"))  # adding Convolution layer\n",
        "eight_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "eight_layers_model.add(layers.Activation('relu'))\n",
        "eight_layers_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Adding dropouts\n",
        "eight_layers_model.add(layers.Dropout(0.30))# adding dropouts\n",
        "\n",
        "# Flattening the output\n",
        "eight_layers_model.add(layers.Flatten(name=\"Flatten_Layer\"))\n",
        "\n",
        "# Fully Connected Layer\n",
        "eight_layers_model.add(layers.Dense(units=128, name=\"FC_Layer_128N\"))\n",
        "eight_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "eight_layers_model.add(layers.Activation('relu'))\n",
        "\n",
        "# Adding dropouts\n",
        "eight_layers_model.add(layers.Dropout(0.40))  # adding dropout\n",
        "\n",
        "# Output Layer\n",
        "eight_layers_model.add(layers.Dense(units=len(class_names), activation=\"softmax\", name=\"Output_Layer\"))  # adding output layer\n",
        "\n",
        "# Compile the model\n",
        "eight_layers_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set callbacks\n",
        "learn_control = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                  patience=3,\n",
        "                                  verbose=1,\n",
        "                                  factor=0.1,\n",
        "                                  min_lr=1e-7)\n",
        "\n",
        "# View the summary of all layers\n",
        "eight_layers_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av15dPZN8_ls"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA1_FF8I8_ls"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "eight_layers_history = eight_layers_model.fit(train_ds ,\n",
        "                    batch_size=batch_size ,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[learn_control],\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaX8zNNU8_ls"
      },
      "source": [
        "Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAGrNtIx8_ls"
      },
      "outputs": [],
      "source": [
        "acc = eight_layers_history.history['accuracy']\n",
        "val_acc = eight_layers_history.history['val_accuracy']\n",
        "\n",
        "loss = eight_layers_history.history['loss']\n",
        "val_loss = eight_layers_history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVN14KOeE8_o"
      },
      "source": [
        "## Model 9 - Ten Convolution layers with Batch Normalization and dropouts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qMDC1wxE8_o"
      },
      "source": [
        "Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk68qZ3_E8_o"
      },
      "outputs": [],
      "source": [
        "# Create the Model\n",
        "ten_layers_model = Sequential(name=\"Melanoma_Detection_Model_More_Layers\")\n",
        "\n",
        "# Adding Rescaling layer\n",
        "ten_layers_model.add(layers.Rescaling(1.0/255.0, offset=0.0, input_shape=(img_height, img_width, 3), name=\"Rescaling_Layer\"))\n",
        "\n",
        "# Adding Data Augmentation\n",
        "ten_layers_model.add(data_augmentation)\n",
        "\n",
        "# First Part\n",
        "ten_layers_model.add(layers.Conv2D(filters=16, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_16F_1\"))  # adding Convolution layer\n",
        "ten_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_model.add(layers.Activation('relu'))\n",
        "ten_layers_model.add(layers.Conv2D(filters=16, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_16F_2\"))  # adding Convolution layer\n",
        "ten_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_model.add(layers.Activation('relu'))\n",
        "ten_layers_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Second Part\n",
        "ten_layers_model.add(layers.Conv2D(filters=32, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_32F_1\"))  # adding Convolution layer\n",
        "ten_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_model.add(layers.Activation('relu'))\n",
        "ten_layers_model.add(layers.Conv2D(filters=32, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_32F_2\"))  # adding Convolution layer\n",
        "ten_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_model.add(layers.Activation('relu'))\n",
        "ten_layers_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Third Part\n",
        "ten_layers_model.add(layers.Conv2D(filters=64, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_64F_1\"))  # adding Convolution layer\n",
        "ten_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_model.add(layers.Activation('relu'))\n",
        "ten_layers_model.add(layers.Conv2D(filters=64, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_64F_2\"))  # adding Convolution layer\n",
        "ten_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_model.add(layers.Activation('relu'))\n",
        "ten_layers_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Fourth Part\n",
        "ten_layers_model.add(layers.Conv2D(filters=128, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_128F_1\"))  # adding Convolution layer\n",
        "ten_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_model.add(layers.Activation('relu'))\n",
        "ten_layers_model.add(layers.Conv2D(filters=128, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_128F_2\"))  # adding Convolution layer\n",
        "ten_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_model.add(layers.Activation('relu'))\n",
        "ten_layers_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Fifth Part\n",
        "ten_layers_model.add(layers.Conv2D(filters=256, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_256F_1\"))  # adding Convolution layer\n",
        "ten_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_model.add(layers.Activation('relu'))\n",
        "ten_layers_model.add(layers.Conv2D(filters=256, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_256F_2\"))  # adding Convolution layer\n",
        "ten_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_model.add(layers.Activation('relu'))\n",
        "ten_layers_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Adding dropouts\n",
        "ten_layers_model.add(layers.Dropout(0.30))# adding dropouts\n",
        "\n",
        "# Flattening the output\n",
        "ten_layers_model.add(layers.Flatten(name=\"Flatten_Layer\"))\n",
        "\n",
        "# Fully Connected Layer\n",
        "ten_layers_model.add(layers.Dense(units=128, name=\"FC_Layer_128N\"))\n",
        "ten_layers_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_model.add(layers.Activation('relu'))\n",
        "\n",
        "# Adding dropouts\n",
        "ten_layers_model.add(layers.Dropout(0.40))  # adding dropout\n",
        "\n",
        "# Output Layer\n",
        "ten_layers_model.add(layers.Dense(units=len(class_names), activation=\"softmax\", name=\"Output_Layer\"))  # adding output layer\n",
        "\n",
        "# Compile the model\n",
        "ten_layers_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set callbacks\n",
        "learn_control = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                  patience=3,\n",
        "                                  verbose=1,\n",
        "                                  factor=0.1,\n",
        "                                  min_lr=1e-7)\n",
        "\n",
        "# View the summary of all layers\n",
        "ten_layers_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3WacKk6E8_o"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPSKQHU-E8_p"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "ten_layers_history = ten_layers_model.fit(train_ds ,\n",
        "                    batch_size=batch_size ,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[learn_control],\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a7EzPBJE8_p"
      },
      "source": [
        "Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ereOXshE8_p"
      },
      "outputs": [],
      "source": [
        "acc = ten_layers_history.history['accuracy']\n",
        "val_acc = ten_layers_history.history['val_accuracy']\n",
        "\n",
        "loss = ten_layers_history.history['loss']\n",
        "val_loss = ten_layers_history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU40gWcctp4N"
      },
      "source": [
        "## Model 10 - Ten Convolution layers with Batch Normalization , dropouts and 50 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50KQi4giui-j"
      },
      "source": [
        "Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7T90wg4Fulqt"
      },
      "outputs": [],
      "source": [
        "# Create the Model\n",
        "ten_layers_50_epochs_model = Sequential(name=\"Melanoma_Detection_Model_More_Layers\")\n",
        "\n",
        "# Adding Rescaling layer\n",
        "ten_layers_50_epochs_model.add(layers.Rescaling(1.0/255.0, offset=0.0, input_shape=(img_height, img_width, 3), name=\"Rescaling_Layer\"))\n",
        "\n",
        "# Adding Data Augmentation\n",
        "ten_layers_50_epochs_model.add(data_augmentation)\n",
        "\n",
        "# First Part\n",
        "ten_layers_50_epochs_model.add(layers.Conv2D(filters=16, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_16F_1\"))  # adding Convolution layer\n",
        "ten_layers_50_epochs_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_50_epochs_model.add(layers.Activation('relu'))\n",
        "ten_layers_50_epochs_model.add(layers.Conv2D(filters=16, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_16F_2\"))  # adding Convolution layer\n",
        "ten_layers_50_epochs_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_50_epochs_model.add(layers.Activation('relu'))\n",
        "ten_layers_50_epochs_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Second Part\n",
        "ten_layers_50_epochs_model.add(layers.Conv2D(filters=32, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_32F_1\"))  # adding Convolution layer\n",
        "ten_layers_50_epochs_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_50_epochs_model.add(layers.Activation('relu'))\n",
        "ten_layers_50_epochs_model.add(layers.Conv2D(filters=32, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_32F_2\"))  # adding Convolution layer\n",
        "ten_layers_50_epochs_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_50_epochs_model.add(layers.Activation('relu'))\n",
        "ten_layers_50_epochs_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Third Part\n",
        "ten_layers_50_epochs_model.add(layers.Conv2D(filters=64, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_64F_1\"))  # adding Convolution layer\n",
        "ten_layers_50_epochs_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_50_epochs_model.add(layers.Activation('relu'))\n",
        "ten_layers_50_epochs_model.add(layers.Conv2D(filters=64, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_64F_2\"))  # adding Convolution layer\n",
        "ten_layers_50_epochs_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_50_epochs_model.add(layers.Activation('relu'))\n",
        "ten_layers_50_epochs_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Fourth Part\n",
        "ten_layers_50_epochs_model.add(layers.Conv2D(filters=128, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_128F_1\"))  # adding Convolution layer\n",
        "ten_layers_50_epochs_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_50_epochs_model.add(layers.Activation('relu'))\n",
        "ten_layers_50_epochs_model.add(layers.Conv2D(filters=128, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_128F_2\"))  # adding Convolution layer\n",
        "ten_layers_50_epochs_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_50_epochs_model.add(layers.Activation('relu'))\n",
        "ten_layers_50_epochs_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Fifth Part\n",
        "ten_layers_50_epochs_model.add(layers.Conv2D(filters=256, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_256F_1\"))  # adding Convolution layer\n",
        "ten_layers_50_epochs_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_50_epochs_model.add(layers.Activation('relu'))\n",
        "ten_layers_50_epochs_model.add(layers.Conv2D(filters=256, kernel_size=(3,3),  padding=\"same\", name=\"Conv2D_Layer_256F_2\"))  # adding Convolution layer\n",
        "ten_layers_50_epochs_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_50_epochs_model.add(layers.Activation('relu'))\n",
        "ten_layers_50_epochs_model.add(layers.MaxPooling2D(pool_size=(2,2)))  # adding Max Pooling layer\n",
        "\n",
        "# Adding dropouts\n",
        "ten_layers_50_epochs_model.add(layers.Dropout(0.30))# adding dropouts\n",
        "\n",
        "# Flattening the output\n",
        "ten_layers_50_epochs_model.add(layers.Flatten(name=\"Flatten_Layer\"))\n",
        "\n",
        "# Fully Connected Layer\n",
        "ten_layers_50_epochs_model.add(layers.Dense(units=128, name=\"FC_Layer_128N\"))\n",
        "ten_layers_50_epochs_model.add(layers.BatchNormalization())  # adding normalization\n",
        "ten_layers_50_epochs_model.add(layers.Activation('relu'))\n",
        "\n",
        "# Adding dropouts\n",
        "ten_layers_50_epochs_model.add(layers.Dropout(0.40))  # adding dropout\n",
        "\n",
        "# Output Layer\n",
        "ten_layers_50_epochs_model.add(layers.Dense(units=len(class_names), activation=\"softmax\", name=\"Output_Layer\"))  # adding output layer\n",
        "\n",
        "# Compile the model\n",
        "ten_layers_50_epochs_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set callbacks\n",
        "learn_control = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                  patience=3,\n",
        "                                  verbose=1,\n",
        "                                  factor=0.1,\n",
        "                                  min_lr=1e-7)\n",
        "\n",
        "# View the summary of all layers\n",
        "ten_layers_50_epochs_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqDNazIkuATx"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QhgVyTFt52i"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "ten_layers_50_epochs_history = ten_layers_50_epochs_model.fit(train_ds ,\n",
        "                    batch_size=batch_size ,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[learn_control],\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlwnNm6EuUlz"
      },
      "source": [
        "Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NYe4shOuUl0"
      },
      "outputs": [],
      "source": [
        "acc = ten_layers_50_epochs_history.history['accuracy']\n",
        "val_acc = ten_layers_50_epochs_history.history['val_accuracy']\n",
        "\n",
        "loss = ten_layers_50_epochs_history.history['loss']\n",
        "val_loss = ten_layers_50_epochs_history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGqK0d2wO8Kp"
      },
      "source": [
        "## Prediction and Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjXCBUk4RETu"
      },
      "source": [
        "Test dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNHDlIoHPDIK"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_test,  # Path to the test data directory\n",
        "    labels='inferred',  # Automatically infer labels from subdirectories\n",
        "    label_mode='int',  # Labels will be integers\n",
        "    class_names=None,  # Infer class names automatically\n",
        "    color_mode='rgb',  # Images are in RGB\n",
        "    batch_size=32,  # Batch size\n",
        "    image_size=(img_height, img_width),  # Image size to resize to\n",
        "    shuffle=False,  # Do not shuffle test data\n",
        "    interpolation='bilinear',  # Interpolation method\n",
        "    follow_links=False  # Follow symbolic links\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQTp8SptSJhp"
      },
      "source": [
        "Prediction on Train Test Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKIVGLY1cUnL"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate accuracy on test data\n",
        "def evaluate_accuracy(model_inp, data_inp):\n",
        "    loss, accuracy = model_inp.evaluate(data_inp, verbose=0)  # Suppress verbose output\n",
        "    return accuracy\n",
        "\n",
        "# Dictionary containing models and their training histories\n",
        "model_dict = {\n",
        "    \"Base Model\": [base_model, base_model_history],\n",
        "    \"Base Model + Augmented Layers\": [aug_layer_model, aug_layer_history],\n",
        "    \"Base Model + Augmented Layers + Balanced Class + Batch Normalization \": [class_blncd_mdl, class_balanced_history],\n",
        "    \"Base Model + Augmented Layers + Balanced Class + Batch Normalization + Controlled LR\": [lr_control_model, lr_control_history],\n",
        "    \"Base Model + Augmented Layers + Balanced Class + Batch Normalization + Increased / Controlled LR\": [increased_lr_ctrl_mdl, increased_lr_control_history],\n",
        "    \"Base Model + Augmented Layers + Balanced Class + Controlled LR + More Epochs\": [more_epoch_model, more_epoch_history],\n",
        "    \"Six Convolution Layers + Augmented Layers + Balanced Class +  Dropouts + Batch Normalization + Controlled LR\": [six_layers_model,six_layers_history],\n",
        "    \"Eight Convolution Layers + Augmented Layers + Balanced Class + Dropouts + Batch Normalization + Controlled LR\": [eight_layers_model,eight_layers_history],\n",
        "    \"Ten Convolution Layers + Augmented Layers + Balanced Class + Dropouts + Batch Normalization + Controlled LR\": [ten_layers_model,ten_layers_history],\n",
        "    \"Ten Convolution Layers + Augmented Layers + Balanced Class + Dropouts + 50 Epochs + Batch Normalization + Controlled LR\": [ten_layers_50_epochs_model,ten_layers_50_epochs_history]\n",
        "}\n",
        "\n",
        "# Create an empty report dataframe with the specified columns\n",
        "report_df = pd.DataFrame(columns=['Model', 'Max Train Accuracy', 'Max Validation Accuracy', 'Test Accuracy'])\n",
        "\n",
        "# Loop through each model and extract the required metrics\n",
        "for key, items in model_dict.items():\n",
        "    # Get the model and history\n",
        "    model = items[0]\n",
        "    history = items[1]\n",
        "\n",
        "    # Get max train accuracy and validation accuracy\n",
        "    max_train_acc = max(history.history['accuracy'])  # Maximum training accuracy\n",
        "    max_val_acc = max(history.history['val_accuracy'])  # Maximum validation accuracy\n",
        "\n",
        "    # Get test accuracy by evaluating the model on the test dataset\n",
        "    test_acc = evaluate_accuracy(model, test_ds)  # Accuracy on the test data\n",
        "\n",
        "    # Create a dictionary with the metrics\n",
        "    df_dict = {\n",
        "        'Model': key,  # Model name\n",
        "        'Max Train Accuracy': round(max_train_acc, 2),  # Max training accuracy\n",
        "        'Max Validation Accuracy': round(max_val_acc, 2),  # Max validation accuracy\n",
        "        'Test Accuracy': round(test_acc, 2)  # Test accuracy\n",
        "    }\n",
        "\n",
        "    # Append row directly using pandas loc to avoid warnings\n",
        "    report_df.loc[len(report_df)] = df_dict  # Append row directly\n",
        "\n",
        "# Increment index to start from 1\n",
        "report_df.index += 1\n",
        "\n",
        "# Set max col displayed\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Display the final sorted report dataframe\n",
        "display(report_df.sort_values(by=['Test Accuracy'], ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiZ5zB56q5NQ"
      },
      "source": [
        "## Check and note library versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b045RtRBEViV"
      },
      "outputs": [],
      "source": [
        "print('numpy' , np.__version__)\n",
        "print('pandas' ,pd.__version__)\n",
        "print('matplotlib', matplotlib.__version__)\n",
        "print('tensorflow' ,tf.__version__)\n",
        "print('keras', keras.__version__)\n",
        "print('augmentor', Augmentor.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZI1_0_xrdR9"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGTydWOhrdR9"
      },
      "source": [
        "Based on the comparison of models, the following conclusions can be made:\n",
        "\n",
        "- Model 9 (Ten Convolution Layers with Augmented Layers, Balanced Class, Dropouts, Batch Normalization, Controlled LR) achieved the highest overall performance, with a validation accuracy of 0.73 and a test accuracy of 0.50. The combination of more layers, dropout regularization, and controlled learning rates made this model the best at generalizing to unseen data.\n",
        "- Model 10 (Ten Convolution Layers with Augmented Layers, Balanced Class, Dropouts, 50 Epochs, Batch Normalization, Controlled LR) had the highest training accuracy (0.72 validation accuracy, 0.48 test accuracy). Although training for more epochs improved training accuracy, the model didn’t generalize as well as Model 9, indicating that increasing the number of epochs alone may not significantly improve test performance.\n",
        "- Models 6 and 8 both performed well with 0.73 validation accuracy and 0.49 test accuracy, suggesting that adding complexity in terms of convolution layers, balanced class handling, and dropout rates enhances performance.\n",
        "- Model 7 (Six Convolution Layers) also showed solid results with a 0.72 validation accuracy and 0.47 test accuracy, but slightly lower than the deeper models.\n",
        "- Models 4 and 5 had moderate performance, achieving validation accuracies of 0.70 and 0.65, respectively, with a test accuracy of 0.45. These models underline the importance of deeper architectures and more sophisticated regularization techniques for achieving better results.\n",
        "- Base Models (1, 2, 3) suffered from overfitting, especially Model 1, which had a high training accuracy (0.91) but very low test accuracy (0.33). This confirms that deeper architectures with data augmentation and dropout regularization are essential for better generalization.\n",
        "\n",
        "- To summarize, deeper convolutional models with controlled learning rates, batch normalization, and dropout regularization, like Model 9, performed the best. While more epochs can help in training accuracy (Model 10), they do not always lead to better test performance.\n",
        "\n",
        "- Overall, applying data augmentation, class balancing, learning rate control, dropout optimization, and deeper architectures significantly enhanced the performance of the CNN models for melanoma detection, with Model 8 emerging as the most balanced in terms of validation and test performance. Further optimization could continue to improve this performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M76Ie2Q51LeJ"
      },
      "source": [
        "### Delete Augmented Images - /output folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoOKmbA9OpG3"
      },
      "outputs": [],
      "source": [
        "import shutil  #  import shutil\n",
        "for i in class_names:\n",
        "    output_folder = path_to_training_dataset + i + '/output'\n",
        "\n",
        "    # Check if the folder exists before attempting to delete\n",
        "    if os.path.exists(output_folder):\n",
        "        shutil.rmtree(output_folder)  # Recursively delete the entire output folder\n",
        "        print(f\"Deleted augmented images for class '{i}' from {output_folder}\")\n",
        "    else:\n",
        "        print(f\"No augmented images found for class '{i}', skipping deletion.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8z6n6TmOYA_"
      },
      "source": [
        "<div align=\"center\">------ End of Notebook -----"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "JfcpIXQZN2Rh",
        "cDBKZG3jPcMc",
        "jbsm5oYiQH_b",
        "BVN14KOeE8_o"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}